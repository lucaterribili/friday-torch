{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install pytorch-lightning\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.utils import shuffle\n",
    "############################## DATASET\n",
    "\n",
    "class SaturdayDataset(Dataset):\n",
    "    def __init__(self, source_sentences, target_sentences, max_len, tokenizer):\n",
    "        self.source_sentences = source_sentences\n",
    "        self.target_sentences = target_sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.filter_invalid_pairs()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_sentences)\n",
    "\n",
    "    def pad_sequence(self, original_source, original_target):\n",
    "        # Encode the source and target sequences\n",
    "        source = original_source[:]\n",
    "        target = original_target[:]\n",
    "        # Insert BOS token at the beginning of the target sequence\n",
    "        target.insert(0, self.tokenizer.bos_id())\n",
    "        target.append(self.tokenizer.eos_id())  # Add EOS token at the end\n",
    "\n",
    "        # Calculate lengths\n",
    "        source_len = len(source)\n",
    "        target_len = len(target)\n",
    "\n",
    "        # Padding for target sequence (add padding after EOS)\n",
    "        remaining_padding_for_target = self.max_len - target_len\n",
    "        if remaining_padding_for_target > 0:\n",
    "            target = target + [self.tokenizer.pad_id()] * remaining_padding_for_target\n",
    "\n",
    "        # Padding for source sequence\n",
    "        remaining_padding_for_source = self.max_len - source_len\n",
    "        if remaining_padding_for_source > 0:\n",
    "            source = source + [self.tokenizer.pad_id()] * remaining_padding_for_source\n",
    "\n",
    "        return source, target\n",
    "\n",
    "    def filter_invalid_pairs(self):\n",
    "        valid_sources = []\n",
    "        valid_targets = []\n",
    "        for src, trg in zip(self.source_sentences, self.target_sentences):\n",
    "            padded_src, padded_trg = self.pad_sequence(src, trg)\n",
    "            # Verifica che entrambi siano validi\n",
    "            if len(padded_src) <= self.max_len and len(padded_trg) <= self.max_len:\n",
    "                valid_sources.append(src)\n",
    "                valid_targets.append(trg)\n",
    "\n",
    "        # Aggiorna le liste con i dati validi\n",
    "        self.source_sentences = valid_sources\n",
    "        self.target_sentences = valid_targets\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.source_sentences[idx]\n",
    "        trg = self.target_sentences[idx]\n",
    "        # Converti le frasi in indici e aggiungi il padding\n",
    "        src_indexes, trg_indexes = self.pad_sequence(src, trg)\n",
    "\n",
    "        return torch.tensor(src_indexes), torch.tensor(trg_indexes)\n",
    "################################# MODEL\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class SaturdayTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1,\n",
    "                 device=None\n",
    "                 ):\n",
    "        super(SaturdayTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout,\n",
    "                                       batch_first=True\n",
    "                                       )\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "        self.device = device\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones((sz, sz), device=self.device)) == 1).transpose(0, 1)\n",
    "        return mask.bool()\n",
    "\n",
    "    def create_mask(self, src, tgt):\n",
    "        device = self.device\n",
    "\n",
    "        src_seq_len = src.shape[1]\n",
    "        tgt_seq_len = tgt.shape[1]\n",
    "\n",
    "        tgt_mask = self.generate_square_subsequent_mask(tgt_seq_len)\n",
    "        src_mask = torch.zeros((src_seq_len, src_seq_len), dtype=torch.bool, device=device)\n",
    "\n",
    "        src_padding_mask = (src == 0).to(device)\n",
    "        tgt_padding_mask = (tgt == 0).to(device)\n",
    "\n",
    "        return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "    def create_mask(self, src, tgt):\n",
    "        src_seq_len = src.shape[1]  # La seconda dimensione è la lunghezza della sequenza\n",
    "        tgt_seq_len = tgt.shape[1]  # La stessa cosa per tgt\n",
    "\n",
    "        # Maschera successiva (tgt_mask) per il decoder\n",
    "        tgt_mask = self.generate_square_subsequent_mask(tgt_seq_len)\n",
    "\n",
    "        # Maschera per il source (src_mask)\n",
    "        src_mask = torch.zeros((src_seq_len, src_seq_len), dtype=torch.bool)\n",
    "\n",
    "        # Maschere di padding\n",
    "        src_padding_mask = (src == 0)  # src.shape è [batch_size, seq_len]\n",
    "        tgt_padding_mask = (tgt == 0)  # tgt.shape è [batch_size, seq_len]\n",
    "\n",
    "        return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "    def forward(self, src: Tensor, tgt: Tensor):\n",
    "        # Creiamo le maschere all'interno del forward\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = self.create_mask(src, tgt)\n",
    "\n",
    "        # Embedding delle sequenze di input e target\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(tgt))\n",
    "\n",
    "        # Passiamo il tutto attraverso il transformer\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, None)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)\n",
    "\n",
    "################################# LIGHTING\n",
    "class LightningTransformer(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embed_dim,\n",
    "            vocab_size,\n",
    "            num_layers,\n",
    "            n_heads,\n",
    "            learning_rate,\n",
    "            sp_model,\n",
    "            max_len,\n",
    "            train_data=None,\n",
    "            val_data=None,\n",
    "            batch_size=50\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.model = SaturdayTransformer(emb_size=embed_dim,\n",
    "                                         src_vocab_size=vocab_size,\n",
    "                                         tgt_vocab_size=vocab_size,\n",
    "                                         num_encoder_layers=num_layers,\n",
    "                                         num_decoder_layers=num_layers,\n",
    "                                         nhead=n_heads,\n",
    "                                         device=self.device\n",
    "                                         )\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=sp_model.pad_id())\n",
    "        self.learning_rate = learning_rate\n",
    "        self.sp_model = sp_model\n",
    "        self.max_len = max_len\n",
    "        self.inputs = None\n",
    "        self.targets = None\n",
    "        self.val_inputs = None\n",
    "        self.val_targets = None\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = sp_model\n",
    "        self.pad_id = sp_model.pad_id()\n",
    "\n",
    "    def forward(self, src, trg_input):\n",
    "        return self.model(src, trg_input)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        src, trg = batch\n",
    "        # src e trg sono ora di forma [batch_size, sequence_length]\n",
    "\n",
    "        # Move tensors to the same device as the model\n",
    "        src = src.to(self.device)\n",
    "        trg = trg.to(self.device)\n",
    "        tgt_input = trg[:, :-1]  # Prendiamo tutto tranne l'ultimo token (l'input per il decoder)\n",
    "\n",
    "\n",
    "        # Passiamo i dati nel modello\n",
    "        logits = self(src, tgt_input)  # Forward pass\n",
    "\n",
    "        # L'output del target è senza il primo token\n",
    "        tgt_out = trg[:, 1:]\n",
    "\n",
    "        # Calcoliamo la loss\n",
    "        loss = self.criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        src, trg = batch\n",
    "        # src e trg sono ora di forma [batch_size, sequence_length]\n",
    "\n",
    "        # Move tensors to the same device as the model\n",
    "        src = src.to(self.device)\n",
    "        trg = trg.to(self.device)\n",
    "        tgt_input = trg[:, :-1]  # Prendiamo tutto tranne l'ultimo token (l'input per il decoder)\n",
    "\n",
    "\n",
    "        # Passiamo i dati nel modello\n",
    "        logits = self(src, tgt_input)  # Forward pass\n",
    "\n",
    "        # L'output del target è senza il primo token\n",
    "        tgt_out = trg[:, 1:]\n",
    "\n",
    "        # Calcoliamo la loss\n",
    "        loss = self.criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        if self.train_data is None:\n",
    "            raise ValueError(\"Train Data not provided.\")\n",
    "        inputs = [pair[0] for pair in self.train_data]\n",
    "        targets = [pair[1] for pair in self.train_data]\n",
    "        # Shuffle data to ensure randomness\n",
    "        self.inputs, self.targets = shuffle(inputs, targets)\n",
    "        if self.val_data is None:\n",
    "            raise ValueError(\"Validation Data not provided.\")\n",
    "        val_inputs = [pair[0] for pair in self.val_data]\n",
    "        val_targets = [pair[1] for pair in self.val_data]\n",
    "        self.val_inputs, self.val_targets = shuffle(val_inputs, val_targets)\n",
    "\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.dataset = SaturdayDataset(self.inputs, self.targets, self.max_len, self.sp_model)\n",
    "            self.val_dataset = SaturdayDataset(self.val_inputs, self.val_targets, self.max_len, self.sp_model)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True, num_workers=5)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=5)\n",
    "########################### INIT\n",
    "tokenizer_path = '/content/drive/MyDrive/models/tokenizer/model.model'\n",
    "sp_model = spm.SentencePieceProcessor()\n",
    "sp_model.Load(tokenizer_path)\n",
    "\n",
    "# Load inputs and targets\n",
    "train_data = np.load('/content/drive/MyDrive/dataset/transformer/dataset.npy', allow_pickle=True)\n",
    "validation_data = np.load('/content/drive/MyDrive/dataset/transformer/dataset_validation.npy', allow_pickle=True)\n",
    "\n",
    "# Parametri del modello\n",
    "embed_dim = 512\n",
    "vocab_size = sp_model.vocab_size()\n",
    "num_layers = 2\n",
    "n_heads = 8\n",
    "learning_rate = 0.0001\n",
    "max_len = 350\n",
    "\n",
    "model = LightningTransformer(\n",
    "    embed_dim=embed_dim,\n",
    "    vocab_size=vocab_size,\n",
    "    num_layers=num_layers,\n",
    "    n_heads=n_heads,\n",
    "    learning_rate=learning_rate,\n",
    "    sp_model=sp_model,\n",
    "    max_len=max_len,\n",
    "    train_data=train_data,\n",
    "    val_data=validation_data,\n",
    "    batch_size=40\n",
    ")\n",
    "\n",
    "model_dir = os.path.join(\"/content/drive/MyDrive/models/transformer/\", \"discussion.ckpt\")\n",
    "\n",
    "if os.path.exists(model_dir):  # Controllo corretto\n",
    "    try:\n",
    "        pretrained = torch.load(model_dir, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.load_state_dict(pretrained[\"state_dict\"], strict=False)\n",
    "        print(\"Il modello è stato caricato correttamente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nel caricare il modello: {e}\")\n",
    "else:\n",
    "    print(\"Il file del modello non esiste nella posizione specificata.\")\n",
    "\n",
    "checkpoint_dir = \"/content/drive/MyDrive/models/transformer/checkpoints/\"\n",
    "\n",
    "# Configurazione dei callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",  # Monitorare la perdita\n",
    "    dirpath=checkpoint_dir,\n",
    "    filename=\"transformer-{epoch:02d}-{val_loss:.2f}\",  # Nome file\n",
    "    save_top_k=10,  # Salva tutti i checkpoint\n",
    "    every_n_epochs=1  # Salvataggio ad ogni epoca\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    verbose=True,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='gpu',\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback]\n",
    ")\n",
    "\n",
    "# Trova tutti i file .ckpt nella cartella\n",
    "checkpoint_files = glob.glob(os.path.join(checkpoint_dir, \"*.ckpt\"))\n",
    "\n",
    "if checkpoint_files:\n",
    "    # Ordina i file per data di modifica (il più recente per ultimo)\n",
    "    latest_checkpoint = max(checkpoint_files, key=os.path.getmtime)\n",
    "    print(f\"Checkpoint trovato: Riprendo l'allenamento da {latest_checkpoint}\")\n",
    "    trainer.fit(model, ckpt_path=latest_checkpoint)\n",
    "else:\n",
    "    print(\"Checkpoint non trovato: Parto da zero.\")\n",
    "    trainer.fit(model)"
   ],
   "id": "7902c74aae5376e8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
